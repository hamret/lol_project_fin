# League of Legends 리그 경쟁 구간(Challenger) LSTM 기반 골드 격차 예측 모델

## 개요

본 프로젝트는 **League of Legends(롤)의 Challenger 구간 게임 데이터**를 분석하여 게임 초반 15분 동안의 라인별(탑/정글/미드/바텀) 플레이 특성을 기반으로 21~25분 시점의 **평균 골드 격차를 예측**하는 시계열 심층 학습 모델입니다. 

총 1088개의 매치 데이터를 학습 데이터로 활용하였으며, **3층 LSTM(Long Short-Term Memory) 신경망**을 이용한 시계열 분석으로 높은 정확도의 예측 성능을 달성합니다. 이 모델은 게임의 극초반 상황에서 중반 이후 경제적 우위를 사전에 파악할 수 있는 도구로 활용될 수 있습니다.

---

## 데이터셋 및 특징 엔지니어링

### 1.1 데이터셋 구성

프로젝트의 기초가 되는 데이터는 다음과 같이 구성됩니다:

- **총 샘플 수**: 최대 1,088개 매치
- **데이터 소스**: Riot Games API를 통한 Challenger 구간 매치 정보 및 타임라인
- **시간 범위**: 게임 초반 0~16분 (16개 타임프레임)
- **예측 타겟**: 21~25분(5분 구간) 평균 골드 격차

각 매치는 **match JSON** 파일과 **timeline JSON** 파일로 구성되며, 이를 통해 시간별 플레이어 상태, 게임 이벤트, 맵 위치 정보 등을 추출합니다.

### 1.2 특징 엔지니어링 (Feature Engineering)

`FeatureBuilderChallengerFull` 클래스가 총 **20개의 특징(피처)**을 라인별로 추출합니다:

#### 기본 경제/성장 지표 (6개)
- `gold`: 현재 누적 골드
- `xp`: 누적 경험치
- `level`: 챔피언 레벨
- `minionsKilled`: 미니언 처치 수(CS)
- `jungleMinionsKilled`: 정글 미니언 처치 수
- `totalDamageToChampions`: 챔피언에게 가한 총 피해량

#### 라인 격차 지표 (2개)
- `gold_diff`: 아군 vs 적군 골드 격차
- `xp_diff`: 아군 vs 적군 경험치 격차

#### 성장률 지표 (2개)
- `gold_rate`: 분당 골드 획득률 (전 프레임 대비 증분)
- `xp_rate`: 분당 경험치 획득률

#### 종합 점수 (2개)
- `power_score`: 골드 + 경험치×0.7로 계산한 종합 권력 점수
- `tempo`: 팀 오브젝트 점수와 정글 개입 압박도의 합산 (팀 게임 템포)

#### 정글 개입 지표 (1개)
- `jungle_pressure`: 정글러와의 근접도 기반 압박 점수
  - 계산식: 유클리드 거리를 기반으로 8000 거리 범위 내 선형 감소 함수 적용
  - 범위: 0~2 (양 팀 정글러 모두 고려)

#### 오브젝트 통합 지표 (1개)
- `objective_score`: 다음 요소들의 가중합
  - Infernal Dragon ×3
  - Mountain Dragon ×2.5
  - Ocean Dragon ×2
  - Cloud Dragon ×1.5
  - Rift Herald ×3
  - Herald Summon ×2
  - Tower Kills ×1.5

#### 드래곤 타입 분류 (4개)
- 용 처치 이벤트 해석으로부터 4가지 드래곤 종류별 처치 횟수
  - `infernal_drake`, `ocean_drake`, `mountain_drake`, `cloud_drake`

#### 기타 오브젝트 (2개)
- `herald_count`: 리프트 전령 처치 수
- `tower_kills`: 타워 파괴 수

#### 입력 데이터 형태
- Shape: (시퀀스 길이=16, 피처=4 라인 × 20) = **(16, 80)**

---

## 모델 아키텍처 및 설계

### 2.1 LSTM 모델 구조

#### 왜 LSTM인가?

시계열 데이터에서 장기 의존성(long-term dependency)을 학습하기 위해 LSTM을 선택했습니다. 게임 초반 15분 동안의 단계적 성장과 누적 이점이 미래의 골드 격차에 영향을 미치므로, 게이트 메커니즘(forget/input/output gates)을 통해 중요 정보를 유지하고 노이즈를 필터링하는 LSTM의 특성이 적합합니다.

#### 모델 계층 구조

```
입력층
├─ Shape: (배치, 16, 80)
│
LSTM 블록 1
├─ LSTM(units=192, return_sequences=True)
├─ LayerNormalization()
│
LSTM 블록 2
├─ LSTM(units=128, return_sequences=True)
├─ Dropout(rate=0.25)
├─ LayerNormalization()
│
LSTM 블록 3
├─ LSTM(units=96, return_sequences=False)
├─ Dropout(rate=0.25)
│
완전연결(Dense) 블록
├─ Dense(64, activation='relu')
├─ Dense(32, activation='relu')
├─ Dense(4)  # 출력: 4 라인의 골드 격차
```

#### 아키텍처 설계 원리

- **계층적 추상화**: 첫 번째 LSTM(192)에서 저수준 시계열 패턴을 학습하고, 두 번째(128)와 세 번째(96) LSTM에서 점진적으로 고수준 특징으로 변환
- **정규화 계층**: LayerNormalization으로 내부 공변량 이동(Internal Covariate Shift)을 줄여 학습 안정성 향상
- **드롭아웃**: 0.25의 확률로 뉴런을 무작위로 비활성화하여 과적합 방지
- **출력 크기**: 최종 4개 뉴런은 TOP, JUNGLE, MID, BOTTOM 라인 각각의 골드 격차 예측

### 2.2 손실함수 및 최적화 전략

#### 손실함수: Mean Squared Error (MSE)

```
L = (1/n) * Σ(y_i - ŷ_i)²
```

회귀 문제(연속값 예측)이므로 MSE를 사용합니다. 큰 오차에 더 큰 페널티를 부여하므로 이상값에 민감합니다.

#### 옵티마이저: Adam (Adaptive Moment Estimation)

- 학습률을 동적으로 조정하여 수렴 속도와 안정성을 개선
- 모멘텀과 RMSprop의 장점을 결합

#### 평가 지표

- **MAE (Mean Absolute Error)**: 실제 스케일에서 평균 절대 오차 (골드 단위)
- **R² Score**: 모델이 설명하는 분산의 비율

```
R² = 1 - Σ(y_i - ŷ_i)² / Σ(y_i - ȳ)²
```

### 2.3 학습 절차

#### 데이터 전처리

1. **StandardScaler** 적용 (입력 X와 출력 Y 각각):
   - 각 피처를 평균 0, 표준편차 1로 정규화
   - 신경망의 안정적인 학습을 위해 필수

2. **train/test 분할**:
   - 85% 학습 데이터 / 15% 테스트 데이터
   - `random_state=42`로 재현성 보장

#### 학습 파라미터

| 파라미터 | 값 |
|---------|-----|
| 에포크 (Epochs) | 180 |
| 배치 크기 (Batch Size) | 32 |
| 조기 종료 모니터링 | val_loss |
| Patience | 12 에포크 |
| 데이터 검증 분할 | test set 사용 |

#### 조기 종료 (Early Stopping)

- 검증 손실(val_loss)이 12 에포크 연속으로 개선되지 않으면 학습 중단
- 최적 가중치를 자동 복원(`restore_best_weights=True`)

---

## 모듈별 상세 설명

### 3.1 main_challenger_full.py (학습 모듈)

이 모듈은 전체 모델 학습 파이프라인을 담당합니다.

#### 주요 함수

##### `r2_score(y_true, y_pred)`
- TensorFlow/Keras 백엔드를 이용한 커스텀 R² 평가 지표 계산
- 텐서 연산으로 구현되어 각 에포크마다 자동으로 계산됨

##### `load_json(path)`
- JSON 파일을 안전하게 로드
- 파일 부재나 형식 오류 시 None 반환
- list 형태일 경우 첫 번째 원소, dict이면 그대로 반환

##### `extract_y_21_25(match, timeline)`
- 21~25분 시점의 각 라인별 평균 골드 격차 추출
- 5개 프레임(21, 22, 23, 24, 25분)의 평균값 계산
- 2개 팀(id=100, id=200) 간의 차이 계산
- 라인 위치 정규화: "MIDDLE"→"MID", "UTILITY"→"BOTTOM"

##### `main()` 함수 (학습 루프)

1. **데이터 로드**: 1~1087번 매치에서 valid한 데이터 추출
2. **특징 추출**: `FeatureBuilderChallengerFull.extract_timeseries()` 호출
3. **데이터 필터링**:
   - 시퀀스 길이 < 16분: 제외
   - Y값(라벨) 없음: 제외
4. **피처 병합**: TOP, JUNGLE, MID, BOTTOM 피처를 시간축으로 연결
5. **정규화 및 분할**: StandardScaler, train_test_split 적용
6. **모델 구축 및 학습**: Sequential API로 LSTM 모델 구성
7. **모델 및 스케일러 저장**:
   - `lstm_models/lstm_challenger_full.h5`
   - `scalers/x_scaler.pkl`, `scalers/y_scaler.pkl`

### 3.2 feature_builder_challenger_full.py (특징 추출 모듈)

이 모듈의 핵심은 원본 게임 데이터에서 머신러닝 모델이 사용할 의미 있는 특징들을 구조화하는 것입니다.

#### `parse_events(timeline)`
- 타임라인에서 모든 게임 이벤트를 수집
- 이벤트 타입: 오브젝트 처치, 타워 파괴, 킬, 데스 등
- 반환: 시간순 이벤트 리스트

#### `extract_objective_features(events)`
- 이벤트에서 오브젝트 관련 정보만 필터링
- 용(Dragon) 처치: 4가지 타입별 분류
  - Infernal, Ocean, Mountain, Cloud 각각 추적
- 전령(Rift Herald): 처치 횟수와 소환 횟수 구분
- 타워(Tower): 파괴된 타워 수
- 최종 오브젝트 점수: 가중합으로 계산 (중요한 오브젝트에 더 높은 가중치)
- 반환: 딕셔너리 형태의 오브젝트 정보

#### `extract_jungle_pressure(match, timeline)`
- 정글러의 맵 움직임을 분석하여 각 라인에 대한 압박도 계산
- 알고리즘:
  1. 양 팀 정글러의 위치 추출 (participantFrames)
  2. 각 라인 플레이어와 정글러 간의 유클리드 거리 계산
  3. 거리 기반 압박도: max(0, (8000 - distance) / 8000)
  4. 1~15분 동안 누적하여 최종 압박도 산출
- 의미: 0에 가까울수록 정글러가 멀고, 2에 가까울수록 양 팀 정글러의 적극적 개입
- 반환: 라인별 압박도 딕셔너리

#### `extract_timeseries(match, timeline)`
- 모든 특징 추출을 통합하는 핵심 함수
- 처리 순서:
  1. 모든 함수를 순차 호출하여 정보 수집
  2. 라인별 플레이어 ID 매핑 구성
  3. 각 분(0~15)마다 다음 계산:
     - 기본 지표: 골드, 경험치, 레벨, CS, 정글 CS, 피해량
     - 라인 격차: 아군과 적군의 지표 차이
     - 성장률: 분 단위 증분
     - 종합 점수: 권력 점수(gold + xp×0.7), 팀 템포
     - 오브젝트 정보: 용, 전령, 타워 등
  4. 각 라인의 시계열 데이터를 numpy 배열로 변환
  5. 반환: 라인별 (16, 20) 형태 배열

#### `_lane_diffs(match, pf, target_lane)` (내부 헬퍼)
- 특정 라인에서 아군과 적군의 골드/경험치 격차 계산
- 양 팀 탐색: team_id==100(블루팀) vs 200(레드팀)

### 3.3 challenger_full_all_in_one.py (예측 및 시각화 모듈)

학습된 모델을 로드하여 새로운 매치에 대해 예측하고 결과를 시각화합니다.

#### `predict_match(match_id)`
- 모델과 스케일러 로드
- 특정 매치 데이터 로드 및 특징 추출
- 특징 정규화
- 모델 예측 수행
- 역정규화하여 실제 골드 단위로 변환
- 반환: (예측값, 매치 정보, 타임라인)

#### `extract_real(match, timeline)`
- 실제 게임 데이터에서 21~25분 골드 격차 추출
- main_challenger_full.py의 `extract_y_21_25()`와 동일한 로직
- 반환: 라인별 실제 골드 격차 딕셔너리

#### 시각화 함수들

##### `plot_bar(pred_real, real)`
- 예측값과 실제값을 나란히 표시하는 막대 그래프
- 직관적인 비교 가능

##### `plot_scatter(pred_real, real)`
- 산점도로 예측-실제 관계 표시
- 대각선은 완벽한 예측을 나타냄
- 분포 패턴으로 편향(bias) 확인 가능

##### `plot_error(pred_real, real)`
- 라인별 절대 오차(|예측 - 실제|) 시각화
- 어느 라인에서 예측이 부정확한지 파악

##### `plot_residual(pred_real, real)`
- 잔차(실제 - 예측) 표시
- 양수: 과소 추정, 음수: 과다 추정
- 오차의 방향성 확인 가능

##### `plot_error_hist(pred_real, real)`
- 오차 분포의 히스토그램
- 오차의 대칭성, 중심, 산포 정도 파악

#### `main(match_id)` 함수
- 모든 처리를 통합 실행
- 예측값과 실제값을 라인별로 출력
- 평균 MAE 계산 및 출력
- 5개의 시각화 함수 순차 실행

---

## 모델 성능 평가

### 4.1 예상되는 성능 지표

이 모델의 설계 특성상 기대하는 성능:

- **MAE (평균 절대 오차)**: 약 150~250 골드
  - 게임 경제 규모(5분 구간, 4개 라인)를 감안하면 적절한 수준
  - 라인별 변동성이 크면 높아질 수 있음

- **R² 점수**: 0.50~0.75
  - 21~25분의 골드 격차는 초반 15분뿐만 아니라 중반 16~20분의 플레이도 영향을 받기 때문에 완벽한 예측은 불가능
  - 하지만 초반 플레이의 중요성을 반영하면 중간 정도 이상의 설명력 기대

### 4.2 성능을 좌우하는 요인

#### 긍정적 요소
- Challenger 구간의 높은 게임 수준과 일관된 전략
- 객관적 지표(골드, 경험치)를 직접 사용
- 시계열 특성을 LSTM으로 적절하게 모델링

#### 제약 요소
- 극초반(0~15분)만 사용: 중반 이후의 여러 변수 미포함
- 플레이어의 예측 불가능한 실수나 극적인 플레이
- 패치 변경으로 인한 메타 게임 변화
- 챔피언 선택, 아이템 빌드 같은 정성적 정보 미포함

---

## 기술적 의의 및 활용

### 5.1 게임 분석의 새로운 차원

이 프로젝트는 다음과 같은 측면에서 의미가 있습니다:

1. **데이터 기반 의사결정**: 게임의 경제적 상황을 정량적으로 예측하여 팀 전략 수립에 활용 가능
2. **시계열 모델링**: 게임 진행 과정의 동적 변화를 포착하는 시계열 분석의 실제 적용
3. **멀티 라인 분석**: 4개 라인의 독립적 특징과 상호작용을 동시에 고려하는 복잡한 시스템 모델링
4. **특징 엔지니어링**: 도메인 지식(게임 규칙, 메타)을 반영한 의미 있는 특징 설계

### 5.2 실무 활용 시나리오

- **프로 팀 코칭**: 게임 초반 플레이를 평가하고 중반 이후 목표 설정
- **선수 성과 평가**: 유사한 골드 격차 상황에서의 플레이 비교 분석
- **게임 밸런싱**: 특정 라인이나 포지션의 강/약점 데이터 기반 파악
- **시뮬레이션**: "만약 초반에 추가 킬을 얻었다면?"과 같은 시나리오 분석

---

## 결론

본 프로젝트는 League of Legends의 **Challenger 구간 빅데이터를 활용한 시계열 심층학습**을 구현한 결과입니다. 3층 LSTM 신경망 구조, 20개의 도메인 기반 특징, 그리고 신중한 데이터 전처리를 통해 게임 초반 15분의 상황으로부터 중반(21~25분)의 경제적 격차를 **유의미한 정확도**로 예측합니다.

특히 다음의 기술적 강점이 있습니다:

1. **복잡한 특징 설계**: 단순 통계를 넘어 정글 압박, 오브젝트 가중합, 팀 템포 등 게임 내 전략을 반영한 특징
2. **견고한 아키텍처**: 계층적 LSTM, 정규화, 드롭아웃을 통한 과적합 방지
3. **모듈화 설계**: 특징 추출, 학습, 예측의 명확한 분리로 유지보수성과 확장성 확보

향후 개선 방향으로는 **챔피언 정보, 아이템 진행, 플레이어 개인 스타일** 같은 추가 특징 통합, **멀티 태스크 러닝**을 통한 킬/데스/골드 동시 예측, 그리고 **트랜스포머 기반 아키텍처**로의 업그레이드 등이 고려될 수 있습니다.

---

## 프로젝트 구조

```
project/
├── main_challenger_full.py           # 모델 학습 스크립트
├── feature_builder_challenger_full.py # 특징 추출 클래스
├── challenger_full_all_in_one.py      # 예측 및 시각화 스크립트
├── match_data/                        # 게임 데이터 (JSON)
│   ├── match_1.json
│   ├── timeline_1.json
│   ├── ...
│   └── match_1087.json
├── lstm_models/                       # 학습된 모델
│   └── lstm_challenger_full.h5
├── scalers/                           # 스케일러 저장소
│   ├── x_scaler.pkl
│   └── y_scaler.pkl
└── README.md                          # 이 파일
```

---

## 사용 방법

### 1. 모델 학습
```bash
python main_challenger_full.py
```
- match_data/ 디렉토리의 JSON 파일을 읽음
- LSTM 모델 학습
- lstm_models/와 scalers/ 디렉토리에 결과 저장

### 2. 특정 매치 예측 및 시각화
```bash
python challenger_full_all_in_one.py --match 1
```
- match_id=1인 매치에 대해 예측 수행
- 5개의 그래프 시각화
- 예측값과 실제값 출력

---

## 기술 스택

| 분류 | 라이브러리 | 버전 |
|-----|---------|------|
| 딥러닝 | TensorFlow/Keras | 2.x |
| 데이터 처리 | NumPy | 1.20+ |
| 머신러닝 | scikit-learn | 0.24+ |
| 시각화 | Matplotlib | 3.3+ |
| 진행률 표시 | tqdm | 4.50+ |

---

## 라이선스

본 프로젝트는 교육 및 연구 목적으로 제작되었습니다.
